1. mapred.job.queue.name: name of the queue
	JobConf.java:
		getQueueName(); get("mapred.job.queue.name", DEFAULT_QUEUE_NAME);
		setQueueName(String queuename); set("mapred.job.queue.name", queueName);
2. mapred.reduce.tasks: reduce instance number, suffle
	
3. mapred.job.name: set the user-specified job name
	JobConf.java:
		setJobName(String name); or set("mapred.job.name", jobName);
4. In hadoop Streaming,
	stream.map.output.fild.separator: set it as the field separator for the map outputs
	stream.num.map.output.key.fields:  
	"stream.reduce.output.field.separator=SEP" and "stream.num.reduce.output.fiels=NUM" to specify the nth field separator in a line of the reduce outputs as the separator between the key and the value.

5. To generate gzip files as your generated ouptut, Pass 
"mapred.output.compress=true" and "mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCode" as options to your streaming job.

6. io.file.buffer.size
	hadoop always set it 4096 by default. org.apache.hadoop.fs.FileSystem.java
	  /**
	   * Opens an FSDataInputStream at the indicated Path.
	   * @param f the file to open
	   */
	  public FSDataInputStream open(Path f) throws IOException {
	    return open(f, getConf().getInt("io.file.buffer.size", 4096));
	  }
7. mapred.linerecordreader.maxlength: in LineRecordReader.java
public LineRecordReader( ... ) {
   this.maxLineLength = job.getInt("mapred.linerecordreader.maxlength",
                                    Integer.MAX_VALUE);
}

8. what is the JobContext? why only get* method is included?
Configuration configuration = context.getConfiguration();

And there is main methdod, 
  /** For debugging.  List non-default properties to the terminal and exit. */
  public static void main(String[] args) throws Exception {
    new Configuration().writeXml(System.out);
  }
in the Configuration.java.
